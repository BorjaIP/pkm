---
title:  Transformers
created: Tuesday 20th June 2023 18:54
aliases: 
tags: 
---
[Transformers](https://huggingface.co/docs/transformers/index) are neural networks that learn context and understanding through sequential data analysis. The **Transformer** models use a modern and evolving mathematical techniques set, generally known as attention or self-attention. This set helps identify how distant data elements influence and depend on one another. Transformers have revolutionized the world of natural language processing (NLP)

The architecture described in the paper [Attention Is All You Need](https://arxiv.org/abs/1706.03762) consists of an encoder and decoder.
## Serialization and save

- Secure problem with [pickle](https://huggingface.co/docs/hub/security-pickle)
- [Safetensors](https://github.com/huggingface/safetensors)
## OCR

- [Donut](https://huggingface.co/docs/transformers/main/en/model_doc/donut) model was proposed in [OCR-free Document Understanding Transformer](https://arxiv.org/abs/2111.15664)\