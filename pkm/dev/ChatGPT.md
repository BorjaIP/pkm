---
title:  ChatGPT
created: Tuesday 20th June 2023 18:30
aliases: 
tags: gpt, llm 
---

| Tool                                                                                  | Description                                                                                                      |
| ------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------- |
| [Awesome-prompts](https://github.com/f/awesome-chatgpt-prompts)                       | ChatGPT prompt curation                                                                                          |
| [Langchain](https://github.com/hwchase17/langchain)                                   | Building applications with LLMs through composability                                                            |
| [Rebuff](https://github.com/woop/rebuff)                                              | Prompt Injection Detector                                                                                        |
| [GPTCache](https://github.com/zilliztech/GPTCache)                                    | Semantic cache for LLMs                                                                                          |
| [Lanarky](https://github.com/ajndkr/lanarky)                                          | Framework to deploy LLM applications in production. Built on top of FastAPI                                      |
| [Text-generation-ui](https://github.com/oobabooga/text-generation-webui)              | Web UI for running Large Language                                                                                |
| [Stable-diffusion-web](https://github.com/AUTOMATIC1111/stable-diffusion-webui)       | Stable Diffusion web UI                                                                                          |
| [ChromaDB](https://github.com/chroma-core/chroma)                                     | The AI-native open-source embedding database                                                                     |
| [Drant](https://github.com/qdrant/qdrant)                                             | Vector Database for the next generation of AI applications                                                       |
| [Faiss](https://github.com/facebookresearch/faiss)                                    | A library for efficient similarity search and clustering of dense vectors                                        |
| [Milvus](https://github.com/milvus-io/milvus)                                         | A cloud-native vector database, storage for next generation AI applications                                      |
| [Argilla](https://github.com/argilla-io/argilla)                                      | The open-source data curation platform for LLMs                                                                  |
| [OpenLLM](https://github.com/bentoml/OpenLLM)                                         | Operating LLMs in production                                                                                     |
| [Lit-GPT](https://github.com/Lightning-AI/lit-gpt)                                    | Supports flash attention, 4-bit and 8-bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training         |
| [vLLM](https://github.com/vllm-project/vllm)                                          | Easy, fast, and cheap LLM serving for everyone                                                                   |
| [Text-generation-inference](https://github.com/huggingface/text-generation-inference) | Large Language Model Text Generation Inference                                                                   |
| [Peft](https://pypi.org/project/peft/)                                                | PEFT: State-of-the-art Parameter-Efficient Fine-Tuning                                                           |
| [LLaVa](https://github.com/haotian-liu/LLaVA)                                         | Visual Instruction Tuning: Large Language-and-Vision Assistant built towards multimodal GPT-4 level capabilities |
| [NExT-GPT](https://github.com/NExT-GPT/NExT-GPT)                                      | Code and models for NExT-GPT: Any-to-Any Multimodal Large Language Model                                         |
| [SkyPilot](https://github.com/skypilot-org/skypilot)                                  | SkyPilot: Run LLMs, AI, and Batch jobs on any cloud                                                              |
| [Zep](https://github.com/getzep/zep)                                                                                      |Fast, scalable building blocks for production LLM apps|

- [The Practical Guides for Large Language Models](https://github.com/Mooler0410/LLMsPracticalGuide)
- [A Watermark for Large Language Models](https://github.com/jwkirchenbauer/lm-watermarking)
- [ChatGPT "DAN" (and other "Jailbreaks")](https://github.com/0xk1h0/ChatGPT_DAN?ref=blog.seclify.com)
- [Query any website](https://www.youtube.com/watch?v=6K1lyyzpxtk)
- [Hosted chatbot specifically focused on question answering](https://github.com/hwchase17/chat-langchain)
- [Understanding the Fundamental Limitations of Vector-Based Retrieval for Building LLM-Powered Chatbots— (**Part 1/3)**](https://medium.com/thirdai-blog/understanding-the-fundamental-limitations-of-vector-based-retrieval-for-building-llm-powered-48bb7b5a57b3)
- [Neural Databases: A Next Generation Context Retrieval System for Building Specialized AI-Agents with ChatGPT — (Part 2/3)](https://medium.com/thirdai-blog/neural-database-next-generation-context-retrieval-system-for-building-specialized-ai-agents-with-861ffa0516e7)
- [Do we really need a specialized vector database?](https://modelz.ai/blog/pgvector)
- [Introducing the World's First Truly Open Instruction-Tuned LLM](https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm)

- [Accelerating Large Language Models with Mixed-Precision Techniques](https://lightning.ai/pages/community/tutorial/accelerating-large-language-models-with-mixed-precision-techniques/)
- [PyTorch & OpenXLA: The Path Forward](https://pytorch.org/blog/pytorch-2.0-xla-path-forward/)
- [7 Ways To Speed Up Inference of Your Hosted LLMs](https://betterprogramming.pub/speed-up-llm-inference-83653aa24c47)
## Frameworks

- [[PrivateGPT]]
- [[ColossalAI]]
- [SeamlessM4T](https://github.com/facebookresearch/seamless_communication)

## Models

- [LLama](https://github.com/facebookresearch/llama)
- [Falcon](https://github.com/Sentdex/Falcon-LLM/)

### Fine-tunning

- [Falcon – A guide to finetune and inference](https://lightning.ai/blog/falcon-a-guide-to-finetune-and-inference/)
- [How To Finetune GPT Like Large Language Models on a Custom Dataset](https://lightning.ai/blog/how-to-finetune-gpt-like-large-language-models-on-a-custom-dataset/)
- [Efficient Fine-Tuning with LoRA: A Guide to Optimal Parameter Selection for Large Language Models](https://www.databricks.com/blog/efficient-fine-tuning-lora-guide-llms)
- [Mistral-7B Fine-Tuning: A Step-by-Step Guide](https://gathnex.medium.com/mistral-7b-fine-tuning-a-step-by-step-guide-52122cdbeca8)
- [Fine-tuning Mistral 7B Model with Your Custom Data](https://python.plainenglish.io/intruct-fine-tuning-mistral-7b-model-with-your-custom-data-7eb22921a483)
- [Optimizing LLMs: A Step-by-Step Guide to Fine-Tuning with PEFT and QLoRA](https://blog.lancedb.com/optimizing-llms-a-step-by-step-guide-to-fine-tuning-with-peft-and-qlora-22eddd13d25b)
- [Argilla - Bringing LLM Fine-Tuning and RLHF to Everyone](https://argilla.io/blog/argilla-for-llms/)
## Lora

- [QLoRA: Efficient Finetuning of Quantized LLMs](https://github.com/artidoro/qlora)
- [Bitsandbytes](https://github.com/TimDettmers/bitsandbytes) - The bitsandbytes is a lightweight wrapper around CUDA custom functions
- [Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA](https://huggingface.co/blog/4bit-transformers-bitsandbytes)
