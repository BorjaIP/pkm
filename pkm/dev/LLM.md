---
title: LLM
created: Monday 5th February 2024 13:24
aliases: 
tags:
  - llm
  - ml
  - ai
---
A **large language model** is a type of [[Artificial Intelligence]] algorithm that applies neural network techniques with lots of parameters to process and understand human languages or text using self-supervised learning techniques. Tasks like text generation, machine translation, summary writing, image generation from texts, machine coding, chat-bots, or Conversational AI are applications of the Large Language Model. Examples of such LLM models are Chat GPT by open AI, BERT (Bidirectional Encoder Representations from Transformers) by Google, etc.

- [Pricing calculator](https://docsbot.ai/tools/gpt-openai-api-pricing-calculator)

| Tool                                                                                  | Description                                                                                                                      |
| ------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------- |
| [Langchain](https://github.com/hwchase17/langchain)                                   | Building applications with LLMs through composability                                                                            |
| [Rebuff](https://github.com/woop/rebuff)                                              | LLM Prompt Injection Detector                                                                                                    |
| [GPTCache](https://github.com/zilliztech/GPTCache)                                    | Semantic cache for LLMs                                                                                                          |
| [LLMSherpa](https://github.com/nlmatics/llmsherpa)                                    | Developer APIs to Accelerate LLM Projects                                                                                        |
| [OpenLLM](https://github.com/bentoml/OpenLLM)                                         | Operating LLMs in production                                                                                                     |
| [vLLM](https://github.com/vllm-project/vllm)                                          | Easy, fast, and cheap LLM serving for everyone                                                                                   |
| [LLaVa](https://github.com/haotian-liu/LLaVA)                                         | LLaVA: Large Language and Vision Assistant                                                                                       |
| [SkyPilot](https://github.com/skypilot-org/skypilot)                                  | Run LLMs, AI, and Batch jobs on any cloud                                                                                        |
| [Zep](https://github.com/getzep/zep)                                                  | Fast, scalable building blocks for production LLM apps                                                                           |
| [Lanarky](https://github.com/ajndkr/lanarky)                                          | Framework to deploy LLM applications in production. Built on top of FastAPI                                                      |
| [Text-generation-ui](https://github.com/oobabooga/text-generation-webui)              | Web UI for running Large Language                                                                                                |
| [Stable-diffusion-web](https://github.com/AUTOMATIC1111/stable-diffusion-webui)       | Stable Diffusion web UI                                                                                                          |
| [Argilla](https://github.com/argilla-io/argilla)                                      | The open-source data curation platform for LLMs                                                                                  |
| [Text-generation-inference](https://github.com/huggingface/text-generation-inference) | LLM Text Generation Inference                                                                                                    |
| [Peft](https://pypi.org/project/peft/)                                                | PEFT: State-of-the-art Parameter-Efficient Fine-Tuning                                                                           |
| [Haystack](https://haystack.deepset.ai/)                                              | LLM orchestration framework to build customizable, production-ready LLM applications                                             |
| [FlowiseAI](https://github.com/FlowiseAI/Flowise)                                     | Drag & drop UI to build your customized LLM flow                                                                                 |
| [Trulens](https://github.com/truera/trulens)                                          | Evaluation and Tracking for LLM Experiments                                                                                      |
| [DocArray](https://github.com/docarray/docarray)                                      | Pydantic for LLM (Represent, send, store and search multimodal data)                                                             |
| [Jina](https://github.com/jina-ai/jina)                                               | Build multimodal AI applications with cloud-native stack                                                                         |
| [Pezzo](https://github.com/pezzolabs/pezzo)                                           | Open-source, developer-first LLMOps platform designed                                                                            |
| [VDP](https://github.com/instill-ai/vdp)                                              | Integrate AI to process unstructured data in the modern data stack                                                               |
| [Leon](https://github.com/leon-ai/leon)                                               | Open-source personal assistant                                                                                                   |
| [Dify](https://github.com/langgenius/dify)                                            | LLM app development platform                                                                                                     |
| [PromptFlow](https://github.com/microsoft/promptflow)                                 | Build high-quality LLM apps                                                                                                      |
| [LangFlow](https://github.com/langflow-ai/langflow)                                   | Langflow is a dynamic graph where each node is an executable unit                                                                |
| [ChatbotUI](https://github.com/mckaywrigley/chatbot-ui)                               | AI chat for every model                                                                                                          |
| [FastChat](https://github.com/lm-sys/FastChat)                                        | An open platform for training, serving, and evaluating large language models. Release repo for **Vicuna** and **Chatbot Arena**. |
| [UltraChat](https://github.com/thunlp/UltraChat)                                      | Large-scale, Informative, and Diverse Multi-round Chat Data                                                                      |
| [LiteLLM](https://github.com/BerriAI/litellm)                                         | Call all LLM APIs using the OpenAI format. (100+ LLMs)                                                                           |
| [AgentGPT](https://github.com/reworkd/AgentGPT)                                       | Assemble, configure, and deploy autonomous AI Agents in your browser                                                             |
| [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)                            | Accessible AI for everyone, to use and to build on.                                                                              |
| [AutoGen](https://github.com/microsoft/autogen)                                       | A programming framework for agentic AI                                                                                           |
| [OpenWeb-UI](https://github.com/open-webui/open-webui)                                | User-friendly WebUI for LLMs                                                                                                     |
<<<<<<< Updated upstream
<<<<<<< Updated upstream
| [Guidance](https://github.com/guidance-ai/guidance)                                   | A guidance language for controlling LLM                                                                                          |


=======
=======
>>>>>>> Stashed changes
<<<<<<< HEAD
| [OpenUI](https://github.com/wandb/openui)                                             | Building UI components with AI                                                                                                   |
[]()
=======
| [Guidance](https://github.com/guidance-ai/guidance)                                   | A guidance language for controlling LLM                                                                                          |


>>>>>>> origin/main
<<<<<<< Updated upstream
>>>>>>> Stashed changes
=======
>>>>>>> Stashed changes
![[llm-tree.jpg]]

## Articles/Talks

- [The Practical Guides for Large Language Models](https://github.com/Mooler0410/LLMsPracticalGuide)
- [A Watermark for Large Language Models](https://github.com/jwkirchenbauer/lm-watermarking)
- [Accelerating Large Language Models with Mixed-Precision Techniques](https://lightning.ai/pages/community/tutorial/accelerating-large-language-models-with-mixed-precision-techniques/)
- [Understanding the Fundamental Limitations of Vector-Based Retrieval for Building LLM-Powered Chatbots— (**Part 1/3)**](https://medium.com/thirdai-blog/understanding-the-fundamental-limitations-of-vector-based-retrieval-for-building-llm-powered-48bb7b5a57b3)
- [Advancing AGI for humanity](https://thegenerality.com/agi/index.html)
- [Prompot-engineering-guide](https://github.com/dair-ai/Prompt-Engineering-Guide)
- [Evaluating Large Language Model (LLM) systems: Metrics, challenges, and best practices](https://medium.com/data-science-at-microsoft/evaluating-llm-systems-metrics-challenges-and-best-practices-664ac25be7e5)
- [LLM-PowerHouse: A Curated Guide for Large Language Models with Custom Training and Inferencing](https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing)

- [[RAG]]

## Tokenization

![[tokenization.png]]

## Best LLM

https://blog.abacus.ai/blog/2023/08/10/create-your-custom-chatgpt-pick-the-best-llm-that-works-for-you/
## Prompt Engineering


- [Awesome Prompt Engineering](https://github.com/promptslab/Awesome-Prompt-Engineering)
- [Awesome GPT Prompt Engineering](https://github.com/snwfdhmp/awesome-gpt-prompt-engineering)
- [8 Types of Prompt Engineering](https://medium.com/@amiraryani/8-types-of-prompt-engineering-5322fff77bdf)
 - [Megatron-LM & Megatron-Core](https://github.com/NVIDIA/Megatron-LM): GPU optimized techniques for training transformer models at-scale
## Text embeddings

[Text Embeddings](https://docs.cohere.ai/embedding-wiki?ref=cohere-ai.ghost.io) give you the ability to turn unstructured text data into a structured form. With embeddings, you can compare two or more pieces of text, be it single words, sentences, paragraphs, or even longer documents. And since these are sets of numbers, the ways you can process and extract insights from them are limited only by your imagination.

- [Text Embeddings Visually Explained](https://cohere.com/blog/text-embeddings)
## Question Answering

- [Hosted chatbot specifically focused on question answering](https://github.com/hwchase17/chat-langchain)
## Models

- [List of Open Sourced Fine-Tuned Large Language Models (LLM)](https://medium.com/geekculture/list-of-open-sourced-fine-tuned-large-language-models-llm-8d95a2e0dc76)
- [Falcon](https://github.com/Sentdex/Falcon-LLM/)

### LLama

- [LLama](https://github.com/facebookresearch/llama)
- [LlamaHub - Get your RAG application rolling in no time](https://llamahub.ai/)
### Transformers

- [[Transformers]]
## Vector Database

- [Do we really need a specialized vector database?](https://modelz.ai/blog/pgvector)

## Parameters

- **Frequency_penalty**: This parameter is used to discourage the model from repeating the same words or phrases too frequently within the generated text. It is a value that is added to the log-probability of a token each time it occurs in the generated text. A higher frequency_penalty value will result in the model being more conservative in its use of repeated tokens.
- **Presence_penalty**: This parameter is used to encourage the model to include a diverse range of tokens in the generated text. It is a value that is subtracted from the log-probability of a token each time it is generated. A higher presence_penalty value will result in the model being more likely to generate tokens that have not yet been included in the generated text.

Both of these parameters can be adjusted to influence the overall quality and diversity of the generated text.