---
title: LLM
created: Monday 5th February 2024 13:24
aliases: 
tags:
  - llm
  - ml
  - ai
---
A **large language model** is a type of [[Artificial Intelligence]] algorithm that applies neural network techniques with lots of parameters to process and understand human languages or text using self-supervised learning techniques. Tasks like text generation, machine translation, summary writing, image generation from texts, machine coding, chat-bots, or Conversational AI are applications of the Large Language Model. Examples of such LLM models are Chat GPT by open AI, BERT (Bidirectional Encoder Representations from Transformers) by Google, etc.

- [Pricing calculator](https://docsbot.ai/tools/gpt-openai-api-pricing-calculator)

| Tool                                                                                  | Description                                                                                                                      |
| ------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------- |
| [Langchain](https://github.com/hwchase17/langchain)                                   | Building applications with LLMs through composability                                                                            |
| [Rebuff](https://github.com/woop/rebuff)                                              | LLM Prompt Injection Detector                                                                                                    |
| [GPTCache](https://github.com/zilliztech/GPTCache)                                    | Semantic cache for LLMs                                                                                                          |
| [LLMSherpa](https://github.com/nlmatics/llmsherpa)                                    | Developer [[API]]s to Accelerate LLM Projects                                                                                    |
| [OpenLLM](https://github.com/bentoml/OpenLLM)                                         | Operating LLMs in production                                                                                                     |
| [vLLM](https://github.com/vllm-project/vllm)                                          | Easy, fast, and cheap LLM serving for everyone                                                                                   |
| [LLaVa](https://github.com/haotian-liu/LLaVA)                                         | LLaVA: Large Language and Vision Assistant                                                                                       |
| [SkyPilot](https://github.com/skypilot-org/skypilot)                                  | Run LLMs, AI, and Batch jobs on any cloud                                                                                        |
| [Zep](https://github.com/getzep/zep)                                                  | Fast, scalable building blocks for production LLM apps                                                                           |
| [Lanarky](https://github.com/ajndkr/lanarky)                                          | Framework to deploy LLM applications in production. Built on top of FastAPI                                                      |
| [Text-generation-ui](https://github.com/oobabooga/text-generation-webui)              | Web UI for running Large Language                                                                                                |
| [Stable-diffusion-web](https://github.com/AUTOMATIC1111/stable-diffusion-webui)       | Stable Diffusion web UI                                                                                                          |
| [Argilla](https://github.com/argilla-io/argilla)                                      | The open-source data curation platform for LLMs                                                                                  |
| [Text-generation-inference](https://github.com/huggingface/text-generation-inference) | LLM Text Generation Inference                                                                                                    |
| [Peft](https://pypi.org/project/peft/)                                                | PEFT: State-of-the-art Parameter-Efficient Fine-Tuning                                                                           |
| [Haystack](https://haystack.deepset.ai/)                                              | LLM orchestration framework to build customizable, production-ready LLM applications                                             |
| [FlowiseAI](https://github.com/FlowiseAI/Flowise)                                     | Drag & drop UI to build your customized LLM flow                                                                                 |
| [Trulens](https://github.com/truera/trulens)                                          | Evaluation and Tracking for LLM Experiments                                                                                      |
| [DocArray](https://github.com/docarray/docarray)                                      | Pydantic for LLM (Represent, send, store and search multimodal data)                                                             |
| [Jina](https://github.com/jina-ai/jina)                                               | Build multimodal AI applications with cloud-native stack                                                                         |
| [Pezzo](https://github.com/pezzolabs/pezzo)                                           | Open-source, developer-first LLMOps platform designed                                                                            |
| [VDP](https://github.com/instill-ai/vdp)                                              | Integrate AI to process unstructured data in the modern data stack                                                               |
| [Leon](https://github.com/leon-ai/leon)                                               | Open-source personal assistant                                                                                                   |
| [Dify](https://github.com/langgenius/dify)                                            | LLM app development platform                                                                                                     |
| [PromptFlow](https://github.com/microsoft/promptflow)                                 | Build high-quality LLM apps                                                                                                      |
| [LangFlow](https://github.com/langflow-ai/langflow)                                   | Langflow is a dynamic graph where each node is an executable unit                                                                |
| [ChatbotUI](https://github.com/mckaywrigley/chatbot-ui)                               | AI chat for every model                                                                                                          |
| [FastChat](https://github.com/lm-sys/FastChat)                                        | An open platform for training, serving, and evaluating large language models. Release repo for **Vicuna** and **Chatbot Arena**. |
| [UltraChat](https://github.com/thunlp/UltraChat)                                      | Large-scale, Informative, and Diverse Multi-round Chat Data                                                                      |
| [LiteLLM](https://github.com/BerriAI/litellm)                                         | Call all LLM APIs using the OpenAI format. (100+ LLMs)                                                                           |
| [AgentGPT](https://github.com/reworkd/AgentGPT)                                       | Assemble, configure, and deploy autonomous AI Agents in your browser                                                             |
| [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)                            | Accessible AI for everyone, to use and to build on.                                                                              |
| [AutoGen](https://github.com/microsoft/autogen)                                       | A programming framework for agentic AI                                                                                           |
| [OpenWeb-UI](https://github.com/open-webui/open-webui)                                | User-friendly WebUI for LLMs                                                                                                     |
| [Guidance](https://github.com/guidance-ai/guidance)                                   | A guidance language for controlling LLM                                                                                          |
| [OpenUI](https://github.com/wandb/openui)                                             | Building UI components with AI                                                                                                   |
| [dsPy](https://github.com/stanfordnlp/dspy)                                           | The framework for programming—not prompting—foundation models                                                                    |
| [Semantic Kernel](https://github.com/microsoft/semantic-kernel)                       | Integrate cutting-edge LLM technology quickly and easily into your apps                                                          |
| [LLMStack](https://github.com/trypromptly/llmstack)                                   | No-code multi-agent framework to build LLM Agents                                                                                |
| [Vanna](https://github.com/vanna-ai/vanna)                                            | Chat with your [[SQL]] database                                                                                                  |
| [Deepseek](https://github.com/deepseek-ai/DeepSeek-Coder-V2)                          | Closed-Source Models in Code Intelligence                                                                                        |
| [LocalAI](https://github.com/mudler/LocalAI)                                          | Open Source OpenAI alternative, Self-hosted                                                                                      |
| [LLama-Factory](https://github.com/hiyouga/LLaMA-Factory)                             | Unify Efficient Fine-Tuning                                                                                                      |
| [Lago](https://github.com/getlago/lago)                                               | Metering and Usage Based Billing API, Consumption tracking                                                                       |
| [Lunary](https://github.com/lunary-ai/lunary)                                         | The production toolkit for LLMs                                                                                                  |
| [OpenLLMetry](https://github.com/traceloop/openllmetry)                               | Open-source observability for your LLM application                                                                               |
| [Evidently](https://github.com/evidentlyai/evidently)                                 | Evaluate and monitor ML models from validation to production                                                                     |
| [Promptify](https://github.com/promptslab/Promptify)                                  | Prompt Engineering and Prompt Versioning                                                                                         |
| [Mem0](https://github.com/mem0ai/mem0)                                                | The memory layer for Personalized AI                                                                                             |
| [Maestro](https://github.com/Doriandarko/maestro)                                     | A framework for Claude Opus to intelligently orchestrate subagents.                                                              |
| [Inspect](https://inspect.ai-safety-institute.org.uk/)                                | An open-source framework for large language model evaluations                                                                    |
| [Anything-llm](https://github.com/Mintplex-Labs/anything-llm)                         | The all-in-one Desktop & Docker AI application with full RAG                                                                     |
| [Gorilla](https://github.com/ShishirPatil/gorilla)                                    | An API store for LLMs                                                                                                            |
| [CrewAI](https://github.com/crewAIInc/crewAI)                                         | Framework for orchestrating role-playing, autonomous AI agents.                                                                  |
| [MLE-agent](https://github.com/MLSysOps/MLE-agent)                                    | Your intelligent companion for seamless AI engineering and research                                                              |
| [Promptfoo](https://github.com/promptfoo/promptfoo)                                   | Test your prompts, agents, and RAGs                                                                                              |
| [Langwatch](https://github.com/langwatch/langwatch)                                   | The ultimate LLM Ops platform - Monitoring, Analytics, Evaluations, Datasets and Prompt Optimization                             |
| [Langfuse](https://github.com/langfuse/langfuse)                                      | Open source LLM engineering platform: LLM Observability, metrics, evals, prompt management, playground, datasets                 |


![[llm_tree.jpg]]

# Articles/Talks

- [The Practical Guides for Large Language Models](https://github.com/Mooler0410/LLMsPracticalGuide)
- [A Watermark for Large Language Models](https://github.com/jwkirchenbauer/lm-watermarking)
- [Accelerating Large Language Models with Mixed-Precision Techniques](https://lightning.ai/pages/community/tutorial/accelerating-large-language-models-with-mixed-precision-techniques/)
- [Understanding the Fundamental Limitations of Vector-Based Retrieval for Building LLM-Powered Chatbots— (**Part 1/3)**](https://medium.com/thirdai-blog/understanding-the-fundamental-limitations-of-vector-based-retrieval-for-building-llm-powered-48bb7b5a57b3)
- [Advancing AGI for humanity](https://thegenerality.com/agi/index.html)
- [Prompot-engineering-guide](https://github.com/dair-ai/Prompt-Engineering-Guide)
- [Evaluating Large Language Model (LLM) systems: Metrics, challenges, and best practices](https://medium.com/data-science-at-microsoft/evaluating-llm-systems-metrics-challenges-and-best-practices-664ac25be7e5)
- [LLM-PowerHouse: A Curated Guide for Large Language Models with Custom Training and Inferencing](https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing)
- [RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application?](https://towardsdatascience.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7)
![[rag_vs_finetuning.png]]
- [[RAG]]

# Tokenization

![[tokenization.png]]

# Best LLM

- https://blog.abacus.ai/blog/2023/08/10/create-your-custom-chatgpt-pick-the-best-llm-that-works-for-you/
- https://huggingface.co/spaces/openlifescienceai/open_medical_llm_leaderboard
- https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard
- https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard
- https://huggingface.co/collections/open-llm-leaderboard/the-big-benchmarks-collection-64faca6335a7fc7d4ffe974a
# Prompt Engineering

- [Awesome Prompt Engineering](https://github.com/promptslab/Awesome-Prompt-Engineering)
- [Awesome GPT Prompt Engineering](https://github.com/snwfdhmp/awesome-gpt-prompt-engineering)
- [8 Types of Prompt Engineering](https://medium.com/@amiraryani/8-types-of-prompt-engineering-5322fff77bdf)
- [Megatron-LM & Megatron-Core](https://github.com/NVIDIA/Megatron-LM): GPU optimized techniques for training transformer models at-scale
# Text embeddings

[Text Embeddings](https://docs.cohere.ai/embedding-wiki?ref=cohere-ai.ghost.io) give you the ability to turn unstructured text data into a structured form. With embeddings, you can compare two or more pieces of text, be it single words, sentences, paragraphs, or even longer documents. And since these are sets of numbers, the ways you can process and extract insights from them are limited only by your imagination.

- [Text Embeddings Visually Explained](https://cohere.com/blog/text-embeddings)

## Embeddings on Multimodal Data

- Embed text, image and video in the **same semantic space with the same dimensionality**.
- Create the capability for join text with image/video for classification for example.

# Nearest Neighbor

**Nearest neighbor search** (**NNS**), as a form of **proximity search**, is the [optimization problem](https://en.wikipedia.org/wiki/Optimization_problem "Optimization problem") of finding the point in a given set that is closest (or most similar) to a given point. Closeness is typically expressed in terms of a dissimilarity function: the less [similar](https://en.wikipedia.org/wiki/Similarity_measure "Similarity measure") the objects, the larger the function values.
## ScaNN

- More efficient for a concrete corpus
# Question Answering

- [Hosted chatbot specifically focused on question answering](https://github.com/hwchase17/chat-langchain)
# Models

- [List of Open Sourced Fine-Tuned Large Language Models (LLM)](https://medium.com/geekculture/list-of-open-sourced-fine-tuned-large-language-models-llm-8d95a2e0dc76)
- [Falcon](https://github.com/Sentdex/Falcon-LLM/)
## LLama

- [LLama](https://github.com/facebookresearch/llama)
- [LlamaHub - Get your RAG application rolling in no time](https://llamahub.ai/)
- [Lit-Llama](https://github.com/Lightning-AI/lit-llama)
## Transformers

- [[Transformers]]
# Fine-Tuning

## RLHF 

![[llm_rlhf.webp]]

Distillation
	- Train a small model to mimic the behavior of a large model
Adapter Tunning
Full Fine Tunning
# Vector Database

- [Do we really need a specialized vector database?](https://modelz.ai/blog/pgvector)
# Parameters

- **Frequency_penalty**: This parameter is used to discourage the model from repeating the same words or phrases too frequently within the generated text. It is a value that is added to the log-probability of a token each time it occurs in the generated text. A higher frequency_penalty value will result in the model being more conservative in its use of repeated tokens.
- **Presence_penalty**: This parameter is used to encourage the model to include a diverse range of tokens in the generated text. It is a value that is subtracted from the log-probability of a token each time it is generated. A higher presence_penalty value will result in the model being more likely to generate tokens that have not yet been included in the generated text.

Both of these parameters can be adjusted to influence the overall quality and diversity of the generated text.