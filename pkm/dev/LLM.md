---
title: LLM
created: Monday 5th February 2024 13:24
aliases: 
tags:
  - llm
  - ml
  - ai
---
A **large language model** is a type of [[Artificial Intelligence]] algorithm that applies neural network techniques with lots of parameters to process and understand human languages or text using self-supervised learning techniques. Tasks like text generation, machine translation, summary writing, image generation from texts, machine coding, chat-bots, or Conversational AI are applications of the Large Language Model. Examples of such LLM models are Chat GPT by open AI, BERT (Bidirectional Encoder Representations from Transformers) by Google, etc.

| Tool                                                                                  | Description                                                                          |
| ------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------ |
| [Langchain](https://github.com/hwchase17/langchain)                                   | Building applications with LLMs through composability                                |
| [Rebuff](https://github.com/woop/rebuff)                                              | LLM Prompt Injection Detector                                                        |
| [GPTCache](https://github.com/zilliztech/GPTCache)                                    | Semantic cache for LLMs                                                              |
| [LLMSherpa](https://github.com/nlmatics/llmsherpa)                                    | Developer APIs to Accelerate LLM Projects                                            |
| [ChromaDB](https://github.com/chroma-core/chroma)                                     | The AI-native open-source embedding database                                         |
| [Drant](https://github.com/qdrant/qdrant)                                             | Vector Database for the next generation of AI applications                           |
| [Faiss](https://github.com/facebookresearch/faiss)                                    | A library for efficient similarity search and clustering of dense vectors            |
| [Milvus](https://github.com/milvus-io/milvus)                                         | A cloud-native vector database, storage for next generation AI applications          |
| [OpenLLM](https://github.com/bentoml/OpenLLM)                                         | Operating LLMs in production                                                         |
| [vLLM](https://github.com/vllm-project/vllm)                                          | Easy, fast, and cheap LLM serving for everyone                                       |
| [LLaVa](https://github.com/haotian-liu/LLaVA)                                         | LLaVA: Large Language and Vision Assistant                                           |
| [SkyPilot](https://github.com/skypilot-org/skypilot)                                  | SkyPilot: Run LLMs, AI, and Batch jobs on any cloud                                  |
| [Zep](https://github.com/getzep/zep)                                                  | Fast, scalable building blocks for production LLM apps                               |
| [Lanarky](https://github.com/ajndkr/lanarky)                                          | Framework to deploy LLM applications in production. Built on top of FastAPI          |
| [Text-generation-ui](https://github.com/oobabooga/text-generation-webui)              | Web UI for running Large Language                                                    |
| [Stable-diffusion-web](https://github.com/AUTOMATIC1111/stable-diffusion-webui)       | Stable Diffusion web UI                                                              |
| [Argilla](https://github.com/argilla-io/argilla)                                      | The open-source data curation platform for LLMs                                      |
| [Text-generation-inference](https://github.com/huggingface/text-generation-inference) | LLM Text Generation Inference                                                        |
| [Peft](https://pypi.org/project/peft/)                                                | PEFT: State-of-the-art Parameter-Efficient Fine-Tuning                               |
| [Haystack](https://haystack.deepset.ai/)                                              | LLM orchestration framework to build customizable, production-ready LLM applications |
| [Verba](https://github.com/weaviate/Verba)                                            | Retrieval Augmented Generation (RAG) chatbot powered by Weaviate                     |
| [FlowiseAI](https://github.com/FlowiseAI/Flowise)                                     | Drag & drop UI to build your customized LLM flow                                     |
| [Trulens](https://github.com/truera/trulens)                                          | Evaluation and Tracking for LLM Experiments                                          |
| [BoCoEL](https://github.com/rentruewang/bocoel)                                       | Bayesian Optimization as a Coverage Tool for Evaluating LLMs                         |
| [DocArray](https://github.com/docarray/docarray)                                      | Pydantic for LLM (Represent, send, store and search multimodal data)                 |
| [Jina](https://github.com/jina-ai/jina)                                               | Build multimodal AI applications with cloud-native stack                             |
| [Pezzo](https://github.com/pezzolabs/pezzo)                                           | Open-source, developer-first LLMOps platform designed                                |
| [VDP](https://github.com/instill-ai/vdp)                                              | Integrate AI to process unstructured data in the modern data stack                   |
| [Leon](https://github.com/leon-ai/leon)                                               | Open-source personal assistant                                                       |
| [Dify](https://github.com/langgenius/dify)                                            | LLM app development platform                                                         |
| [PromptFlow](https://github.com/microsoft/promptflow)                                 | Build high-quality LLM apps                                                          |
| [LangFlow](https://github.com/langflow-ai/langflow)                                   | Langflow is a dynamic graph where each node is an executable unit                    |
| [ChatbotUI](https://github.com/mckaywrigley/chatbot-ui)                               | AI chat for every model                                                              |


![[llm-tree.jpg]]

## Articles/Talks

- [The Practical Guides for Large Language Models](https://github.com/Mooler0410/LLMsPracticalGuide)
- [A Watermark for Large Language Models](https://github.com/jwkirchenbauer/lm-watermarking)
- [Accelerating Large Language Models with Mixed-Precision Techniques](https://lightning.ai/pages/community/tutorial/accelerating-large-language-models-with-mixed-precision-techniques/)
- [Understanding the Fundamental Limitations of Vector-Based Retrieval for Building LLM-Powered Chatbots— (**Part 1/3)**](https://medium.com/thirdai-blog/understanding-the-fundamental-limitations-of-vector-based-retrieval-for-building-llm-powered-48bb7b5a57b3)
- [Advancing AGI for humanity](https://thegenerality.com/agi/index.html)
- [Prompot-engineering-guide](https://github.com/dair-ai/Prompt-Engineering-Guide)
- [Evaluating Large Language Model (LLM) systems: Metrics, challenges, and best practices](https://medium.com/data-science-at-microsoft/evaluating-llm-systems-metrics-challenges-and-best-practices-664ac25be7e5)

## Training

 - [Megatron-LM & Megatron-Core](https://github.com/NVIDIA/Megatron-LM): GPU optimized techniques for training transformer models at-scale
## RAG

- [What is a RAG?](https://python.langchain.com/v0.1/docs/use_cases/question_answering/?ref=blog.langchain.dev)
- [Evaluating RAG pipelines with Ragas + LangSmith](https://blog.langchain.dev/evaluating-rag-pipelines-with-ragas-langsmith/)
- [RAGAS](https://github.com/explodinggradients/ragas): Evaluation framework for your Retrieval Augmented Generation (RAG) pipelines
## Text embeddings

[Text Embeddings](https://docs.cohere.ai/embedding-wiki?ref=cohere-ai.ghost.io) give you the ability to turn unstructured text data into a structured form. With embeddings, you can compare two or more pieces of text, be it single words, sentences, paragraphs, or even longer documents. And since these are sets of numbers, the ways you can process and extract insights from them are limited only by your imagination.

- [Text Embeddings Visually Explained](https://cohere.com/blog/text-embeddings)
## Question Answering

- [Hosted chatbot specifically focused on question answering](https://github.com/hwchase17/chat-langchain)
## Models

- [List of Open Sourced Fine-Tuned Large Language Models (LLM)](https://medium.com/geekculture/list-of-open-sourced-fine-tuned-large-language-models-llm-8d95a2e0dc76)
- [Falcon](https://github.com/Sentdex/Falcon-LLM/)

### LLama

- [LLama](https://github.com/facebookresearch/llama)
- [LlamaHub - Get your RAG application rolling in no time](https://llamahub.ai/)
### Transformers

- [[Transformers]]

## Vector Database

- [Do we really need a specialized vector database?](https://modelz.ai/blog/pgvector)